knitr::opts_chunk$set(echo = TRUE)
install.packages("ropenaq")
install.packages("openaq")
install.packages("devtools")  # Install devtools if not already installed
devtools::install_github("ropensci/openaq")
library(openaq)
install.packages("httr")
install.packages("jsonlite")
# Trying to use API to scrape
# Load libraries
library(httr)
library(jsonlite)
# Define the base URL for OpenAQ API
base_url <- "https://api.openaq.org/v2/measurements"
# Define parameters for the API query
params <- list(
country = "IN",          # Filter by country (e.g., India)
parameter = "pm25",      # Filter by pollutant (e.g., PM2.5)
date_from = "2023-12-01", # Start date
date_to = "2023-12-31",   # End date
limit = 100              # Limit results per page
)
# Initialize a list to store results
results <- list()
# Fetch data in a loop (pagination)
page <- 1
while (TRUE) {
params$page <- page  # Add page parameter to query
# Make the API request
response <- GET(base_url, query = params)
# Parse the response content
data <- fromJSON(content(response, "text"))
# Check if there are results
if (length(data$results) == 0) break
# Store the results
results <- c(results, data$results)
# Print progress
cat("Fetched page:", page, "with", length(data$results), "records\n")
# Introduce a delay to avoid overloading the server
Sys.sleep(1)  # 1-second delay (adjust based on API rate limits)
# Increment the page number
page <- page + 1
}
# Combine results into a data frame
results_df <- do.call(rbind, lapply(results, as.data.frame))
# Display the first 5 rows of the data
print(head(results_df, 5))
print(content(response, "text", encoding = "UTF-8"))
# Trying to use API to scrape
# Load libraries
library(httr)
library(jsonlite)
# Store API key
api_key <- fcf1608ecf90df9ffc7a8a2e770adc080c5623638312f1e7543ef9211be00795
# Trying to use API to scrape
# Load libraries
library(httr)
library(jsonlite)
# Store API key
api_key <- "fcf1608ecf90df9ffc7a8a2e770adc080c5623638312f1e7543ef9211be00795"
# Define end point (new delhi)
url <- "https://api.openaq.org/v3/locations/8118"
# Make the request
# Make the GET request
response <- GET(
url,
add_headers(`X-API-Key` = api_key)  # Include the API key in the header
)
# Check the status of the response
if (status_code(response) == 200) {
cat("Request successful!\n")
} else {
stop("Request failed: ", status_code(response), "\n", content(response, "text"))
}
# Parse the JSON content
data <- fromJSON(content(response, "text", encoding = "UTF-8"))
# View the parsed data
print(data)
View(data)
# Trying to use API to scrape
# Load libraries
library(httr)
library(jsonlite)
# Store API key
api_key <- "fcf1608ecf90df9ffc7a8a2e770adc080c5623638312f1e7543ef9211be00795"
# Define end point (new delhi)
url <- "https://api.openaq.org/v3/locations/8118"
# Make the request
# Make the GET request
response <- GET(
url,
add_headers(`X-API-Key` = api_key)  # Include the API key in the header
)
# Check the status of the response
if (status_code(response) == 200) {
cat("Request successful!\n")
} else {
stop("Request failed: ", status_code(response), "\n", content(response, "text"))
}
# Parse the JSON content
data <- fromJSON(content(response, "text", encoding = "UTF-8"))
# View the parsed data
print(data)
# Clean and display the output
cat("Location Details:\n")
cat("-----------------\n")
cat("Name: ", result$name, "\n")
str(data)
# Trying to use API to scrape
# Load libraries
library(httr)
library(jsonlite)
# Store API key
api_key <- "fcf1608ecf90df9ffc7a8a2e770adc080c5623638312f1e7543ef9211be00795"
# Define end point (new delhi)
url <- "https://api.openaq.org/v3/locations/8118"
# Make the request
# Make the GET request
response <- GET(
url,
add_headers(`X-API-Key` = api_key)  # Include the API key in the header
)
# Check the status of the response
if (status_code(response) == 200) {
cat("Request successful!\n")
} else {
stop("Request failed: ", status_code(response), "\n", content(response, "text"))
}
# Parse the JSON content
data <- fromJSON(content(response, "text", encoding = "UTF-8"))
# View the parsed data
print(data)
# Trying to use API to scrape
# Load libraries
library(httr)
library(jsonlite)
# Store API key
api_key <- "fcf1608ecf90df9ffc7a8a2e770adc080c5623638312f1e7543ef9211be00795"
# Define end point (new delhi)
url <- "https://api.openaq.org/v3/locations/152"
# Make the request
# Make the GET request
response <- GET(
url,
add_headers(`X-API-Key` = api_key)  # Include the API key in the header
)
# Check the status of the response
if (status_code(response) == 200) {
cat("Request successful!\n")
} else {
stop("Request failed: ", status_code(response), "\n", content(response, "text"))
}
# Parse the JSON content
data <- fromJSON(content(response, "text", encoding = "UTF-8"))
# View the parsed data
print(data)
# Trying to use API to scrape
# Load libraries
library(httr)
library(jsonlite)
# Store API key
api_key <- "fcf1608ecf90df9ffc7a8a2e770adc080c5623638312f1e7543ef9211be00795"
# Define end point (new delhi)
url <- "https://api.openaq.org/v3/locations/2453319"
# Make the request
# Make the GET request
response <- GET(
url,
add_headers(`X-API-Key` = api_key)  # Include the API key in the header
)
# Check the status of the response
if (status_code(response) == 200) {
cat("Request successful!\n")
} else {
stop("Request failed: ", status_code(response), "\n", content(response, "text"))
}
# Parse the JSON content
data <- fromJSON(content(response, "text", encoding = "UTF-8"))
# View the parsed data
print(data)
# Trying to use API to scrape
# Load libraries
library(httr)
library(jsonlite)
# Store API key
api_key <- "fcf1608ecf90df9ffc7a8a2e770adc080c5623638312f1e7543ef9211be00795"
# Define end point (new delhi)
url <- "https://explore.openaq.org/?location=154&parameter=pm25#12/51.52254/-0.15458"
# Define the parameters for the request
params <- list(
location_id = "2453319", # Location ID for New Delhi
parameter = "pm25",      # We're interested in PM2.5 data
date_from = "2024-12-01T00:00:00Z",  # Start date (1st December 2024)
date_to = "2024-12-14T23:59:59Z",    # End date (14th December 2024)
limit = 1000,            # Limit the number of data points returned
page = 1                 # Start with the first page of results
)
# Make the GET request
response <- GET(
url,
add_headers(`X-API-Key` = api_key)  # Include the API key in the header
)
# Check the status of the response
if (status_code(response) == 200) {
cat("Request successful!\n")
} else {
stop("Request failed: ", status_code(response), "\n", content(response, "text"))
}
# Parse the JSON content
data <- fromJSON(content(response, "text", encoding = "UTF-8"))
# Trying to use API to scrape
# Load libraries
library(httr)
library(jsonlite)
# Store API key
api_key <- "fcf1608ecf90df9ffc7a8a2e770adc080c5623638312f1e7543ef9211be00795"
# Define end point (new delhi)
url <- "https://explore.openaq.org/?location=154&parameter=pm25#12/51.52254/-0.15458"
# Define the parameters for the request
params <- list(
location_id = "2453319", # Location ID for New Delhi
parameter = "pm25",      # We're interested in PM2.5 data
date_from = "2024-12-01T00:00:00Z",  # Start date (1st December 2024)
date_to = "2024-12-14T23:59:59Z",    # End date (14th December 2024)
limit = 1000,            # Limit the number of data points returned
page = 1                 # Start with the first page of results
)
# Make the GET request
response <- GET(
url,
add_headers(`X-API-Key` = api_key)  # Include the API key in the header
)
# Check the status of the response
if (status_code(response) == 200) {
cat("Request successful!\n")
} else {
stop("Request failed: ", status_code(response), "\n", content(response, "text"))
}
# Parse the JSON content
data <- fromJSON(content(response, "text", encoding = "UTF-8"))
# Trying to use API to scrape
# Load libraries
library(httr)
library(jsonlite)
# Store API key
api_key <- "fcf1608ecf90df9ffc7a8a2e770adc080c5623638312f1e7543ef9211be00795"
# Define end point (new delhi)
url <- "https://api.openaq.org/v3/measurements"
# Define the parameters for the request
params <- list(
location_id = "2453319", # Location ID for New Delhi
parameter = "pm25",      # We're interested in PM2.5 data
date_from = "2024-12-01T00:00:00Z",  # Start date (1st December 2024)
date_to = "2024-12-14T23:59:59Z",    # End date (14th December 2024)
limit = 1000,            # Limit the number of data points returned
page = 1                 # Start with the first page of results
)
# Make the GET request
response <- GET(
url,
add_headers(`X-API-Key` = api_key)  # Include the API key in the header
)
# Check the status of the response
if (status_code(response) == 200) {
cat("Request successful!\n")
} else {
stop("Request failed: ", status_code(response), "\n", content(response, "text"))
}
# Trying to use API to scrape
# Load libraries
library(httr)
library(jsonlite)
# Store API key
api_key <- "fcf1608ecf90df9ffc7a8a2e770adc080c5623638312f1e7543ef9211be00795"
# Define end point (new delhi)
url <- "https://api.openaq.org/v3/measurements"
# Define the parameters for the request
params <- list(
location_id = "2453319", # Location ID for New Delhi
parameter = "pm25",      # We're interested in PM2.5 data
date_from = "2024-12-01T00:00:00Z",  # Start date (1st December 2024)
date_to = "2024-12-14T23:59:59Z",    # End date (14th December 2024)
limit = 1000,            # Limit the number of data points returned
page = 1                 # Start with the first page of results
)
# Make the GET request
response <- GET(
url,
add_headers(`X-API-Key` = api_key)  # Include the API key in the header
)
# Define the parameters for the request
params <- list(
location_id = "2453319", # Location ID for New Delhi
parameter = "pm25",      # We're interested in PM2.5 data
date_from = "2024-12-01T00:00:00Z",  # Start date (1st December 2024)
date_to = "2024-12-14T23:59:59Z",    # End date (14th December 2024)
limit = 1000,            # Limit the number of data points returned
page = 1                 # Start with the first page of results
)
# Make the GET request
response <- GET(
url,
add_headers(`X-API-Key` = api_key),  # Include the API key in the header
query = params                     # Add query parameters for filtering the data
)
# Check the status of the response
if (status_code(response) == 200) {
cat("Request successful!\n")
# Parse the JSON content
data <- fromJSON(content(response, "text", encoding = "UTF-8"))
# Extract the measurements data
measurements <- data$results
# View the first few rows to ensure the data is correct
print(head(measurements))
# Check if there are any measurements
if (length(measurements) > 0) {
# Calculate the mean of the PM2.5 values
mean_pm25 <- mean(sapply(measurements, function(x) x$value), na.rm = TRUE)
cat("Mean PM2.5 from 1st to 14th December 2024:", mean_pm25, "µg/m³\n")
} else {
cat("No data found for the specified date range.\n")
}
} else {
cat("Request failed with status code: ", status_code(response), "\n")
# Print the raw content of the response to diagnose the issue
print(content(response, "text", encoding = "UTF-8"))
}
# Trying to use API to scrape
# Load libraries
library(httr)
library(jsonlite)
# Store API key
api_key <- "fcf1608ecf90df9ffc7a8a2e770adc080c5623638312f1e7543ef9211be00795"
# Define end point (new delhi)
url <- "https://api.openaq.org/v3/locations/2453319"
# Make the GET request
response <- GET(
url,
add_headers(`X-API-Key` = api_key)  # Include the API key in the header
)
# Check the status of the response
if (status_code(response) == 200) {
cat("Request successful!\n")
} else {
stop("Request failed: ", status_code(response), "\n", content(response, "text"))
}
# Parse the JSON content
data <- fromJSON(content(response, "text", encoding = "UTF-8"))
# View the parsed data
print(data)
# Trying to use API to scrape
# Load libraries
library(httr)
library(jsonlite)
# Store API key
api_key <- "396ababd691ce8faa7317a3b69e14bb4c3f20f32"
# Define API key and city
url <- "https://api.openaq.org/v3/locations/2453319"
city <- "london"
# Construct the API URL for London
url <- paste0("https://api.waqi.info/feed/", city, "/?token=", api_key)
# Make the GET request to the AQICN API
response <- GET(url)
# Parse the JSON response
data <- fromJSON(content(response, "text"))
# Check if the response is successful
if (data$status == "ok") {
# Extract relevant information from the response
aqi <- data$data$aqi
pm25 <- data$data$iaqi$pm25$v
pm10 <- data$data$iaqi$pm10$v
# Print the air quality data
cat("Air Quality Index (AQI) in London:", aqi, "\n")
cat("PM2.5 Level:", pm25, "µg/m³\n")
cat("PM10 Level:", pm10, "µg/m³\n")
cat("Timestamp of data:", data$data$time$s, "\n")
} else {
cat("Failed to retrieve data")
}
# Trying to use API to scrape
# Load libraries
library(httr)
library(jsonlite)
# Store API key
api_key <- "396ababd691ce8faa7317a3b69e14bb4c3f20f32"
# Define API key and city
url <- "https://api.openaq.org/v3/locations/2453319"
city <- "miami"
# Construct the API URL for London
url <- paste0("https://api.waqi.info/feed/", city, "/?token=", api_key)
# Make the GET request to the AQICN API
response <- GET(url)
# Parse the JSON response
data <- fromJSON(content(response, "text"))
# Check if the response is successful
if (data$status == "ok") {
# Extract relevant information from the response
aqi <- data$data$aqi
pm25 <- data$data$iaqi$pm25$v
pm10 <- data$data$iaqi$pm10$v
# Print the air quality data
cat("Air Quality Index (AQI) in London:", aqi, "\n")
cat("PM2.5 Level:", pm25, "µg/m³\n")
cat("PM10 Level:", pm10, "µg/m³\n")
cat("Timestamp of data:", data$data$time$s, "\n")
} else {
cat("Failed to retrieve data")
}
